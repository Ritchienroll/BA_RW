{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import os\n",
    "from osgeo import gdal, ogr, gdal_array # I/O image data\n",
    "import joblib\n",
    "import numpy as np # math and array handling\n",
    "import matplotlib.pyplot as plt # plot figures\n",
    "from matplotlib.colors import ListedColormap # to import certain defined color palettes for plotting your results\n",
    "from sklearn.ensemble import RandomForestClassifier # classifier\n",
    "import pandas as pd # handling large data as table sheets\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix  # calculating measures for accuracy assessment\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skimage import exposure  # for adjustment of rasterstack (histogram equalization, etc)\n",
    "\n",
    "# Tell GDAL to throw Python exceptions, and register all drivers\n",
    "gdal.UseExceptions()\n",
    "gdal.AllRegister()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where my data is located\n",
    "folder_src = r\"C:\\Users\\rwolff\\Documents\\Lac Bam SSD\\Test\\Neuer Ordner\\TDX_3\"\n",
    "folder_src_shape = r\"C:\\Users\\rwolff\\Documents\\Lac Bam SSD\\Shapefiles classification  angepasste Klassen\"\n",
    "\n",
    "# path where I want to save my results \n",
    "folder_results = r\"E:\\CSV_27 Aufnahmen\\TSX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many cores should be used?\n",
    "n_cores = -1\n",
    "# -1 -> all available cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "directory = folder_src\n",
    "directory_shapes = folder_src_shape\n",
    "iterator = 0\n",
    "\n",
    "for filename_tif, filename_shape in zip(os.listdir(directory),[f for f in os.listdir(directory_shapes) if f.endswith('.shp')]):\n",
    "  file = os.path.join(directory, filename_tif)\n",
    "  if os.path.isfile(file):\n",
    "    print(file)\n",
    "    s2_stack=file\n",
    "    print(s2_stack)\n",
    "    filename = filename_tif\n",
    "    # load image data\n",
    "    #In this script we are Using gdal.open() instead of rio.open()\n",
    "    img_ds = gdal.Open(s2_stack, gdal.GA_ReadOnly)\n",
    "\n",
    "    img = np.zeros((img_ds.RasterYSize, img_ds.RasterXSize, img_ds.RasterCount),\n",
    "               gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "    for b in range (img.shape[2]):\n",
    "        img[:, :, b] = img_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "\n",
    "    print(\"Raster format is:\", gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "    \n",
    "# store the variables above in a more meaningful way. You will use these variables later.\n",
    "    row = img_ds.RasterYSize\n",
    "    col = img_ds.RasterXSize\n",
    "    band_number = img_ds.RasterCount\n",
    "    \n",
    "    print(\"Raster number of rows: {}\".format(row))\n",
    "    print(\"Raster number of columns: {}\".format(col))\n",
    "    print(\"Raster number of bands: {}\".format(band_number))\n",
    "    \n",
    "# Take our full image and reshape into long 2d array (nrow * ncol, nband) for classification\n",
    "    #new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n",
    "    #img_as_array = img[:, :, : int(img.shape[2])].reshape(new_shape)\n",
    "\n",
    "    #print('Reshaped from {o} to {n}'.format(o=img.shape, n=img_as_array.shape))\n",
    "    \n",
    "    training = folder_src_shape + \"\\\\\" + filename_shape\n",
    "# what is the numerical attribute of your classes in the shapefile?\n",
    "    attribute = 'id'\n",
    "# load training data and show all shapefile attributes\n",
    "    print(training)\n",
    "    shape_dataset = ogr.Open(training)\n",
    "    shape_layer = shape_dataset.GetLayer()\n",
    "\n",
    "# extract the names of all attributes (fieldnames) in the shape file\n",
    "    attributes = [] # empty list where the attributes will be saved\n",
    "    ldefn = shape_layer.GetLayerDefn() # encapsulates the attribute schema of the features of the layer\n",
    "    for n in range(ldefn.GetFieldCount()):\n",
    "        fdefn = ldefn.GetFieldDefn(n)\n",
    "        attributes.append(fdefn.name)\n",
    "\n",
    "# print the attributes\n",
    "    print('Available attributes in the shapefile are: {}'.format(attributes))\n",
    "# copy the structure of your Sentinel2 image to pass this information to the new rasterized polygons\n",
    "    mem_drv = gdal.GetDriverByName('MEM')\n",
    "    mem_raster = mem_drv.Create('',img_ds.RasterXSize,img_ds.RasterYSize,1,gdal.GDT_Byte)\n",
    "    mem_raster.SetProjection(img_ds.GetProjection())\n",
    "    mem_raster.SetGeoTransform(img_ds.GetGeoTransform())\n",
    "    mem_band = mem_raster.GetRasterBand(1)\n",
    "    mem_band.Fill(0)\n",
    "    mem_band.SetNoDataValue(0)\n",
    "    \n",
    "    \n",
    "\n",
    "    att_ = 'ATTRIBUTE='+attribute\n",
    "\n",
    "# rasterize your polygons\n",
    "    err = gdal.RasterizeLayer(mem_raster, [1], shape_layer, None, None, [1], [att_,\"ALL_TOUCHED=TRUE\"])\n",
    "    assert err == gdal.CE_None\n",
    "\n",
    "    roi = mem_raster.ReadAsArray()\n",
    "# Number of training pixels:\n",
    "    n_samples = (roi > 0).sum()\n",
    "    print('{n} training samples'.format(n=n_samples))\n",
    "\n",
    "# What are our classification labels?\n",
    "    labels = np.unique(roi[roi > 0])\n",
    "    print('training data include {n} classes: {classes}'.format(n=labels.size, classes=labels))\n",
    "\n",
    "    # Subset the image dataset with the training image = X\n",
    "    # Mask the classes on the training dataset = y\n",
    "    # These will have n_samples rows\n",
    "    \n",
    "\n",
    "    X = img[roi > 0, :]\n",
    "    y = roi[roi > 0]\n",
    "    \n",
    "    if iterator == 0:\n",
    "        X_concat = X.copy()\n",
    "        y_concat = y.copy()\n",
    "    else:      \n",
    "        X_concat1 = X_concat.copy()\n",
    "        y_concat1 = y_concat.copy()\n",
    "        X_concat = np.concatenate((X_concat1, X), axis=0)\n",
    "        y_concat = np.concatenate((y_concat1, y), axis=0)\n",
    "        \n",
    "    iterator+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klassen,Anzahl=np.unique(y_concat , return_index=False, return_inverse=False, return_counts=True, axis=None)\n",
    "print(Anzahl)\n",
    "print(klassen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAFE X_concat to CSV\n",
    "\n",
    "array_X = X_concat\n",
    "df = pd.DataFrame(array_X)\n",
    "display(df) #Alternative zu print()\n",
    "\n",
    "#1. Schritt: CSV-File wird geschrieben\n",
    "output_name = 'X_concat TDX_3test.csv'\n",
    "output_folder = r\"E:\\CSV Data\\TSX\"\n",
    "output_data = os.path.join(output_folder, output_name)\n",
    "if os.path.isfile(output_data):   #checks, if file already exists\n",
    "    print (\"\\nFile already exists in {}! Image was not saved!\".format(output_data))\n",
    "else:\n",
    "    df.to_csv(output_data)\n",
    "    print (\"\\nCsv-file was successfully saved in {}!\".format(output_data))\n",
    "    \n",
    "## SAFE y_concat to CSV\n",
    "\n",
    "array_y = y_concat\n",
    "df = pd.DataFrame(array_y)\n",
    "display(df) #Alternative zu print()\n",
    "\n",
    "#1. Schritt: CSV-File wird geschrieben\n",
    "output_name = 'y_concat TDX_3test.csv'\n",
    "output_folder = r\"E:\\CSV Data\\TSX\"\n",
    "output_data = os.path.join(output_folder, output_name)\n",
    "if os.path.isfile(output_data):   #checks, if file already exists\n",
    "    print (\"\\nFile already exists in {}! Image was not saved!\".format(output_data))\n",
    "else:\n",
    "    df.to_csv(output_data)\n",
    "    print (\"\\nCsv-file was successfully saved in {}!\".format(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klassen,Anzahl=np.unique(array_y, return_index=False, return_inverse=False, return_counts=True, axis=None)\n",
    "print(Anzahl)\n",
    "print(klassen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
