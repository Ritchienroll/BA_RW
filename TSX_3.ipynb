{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import os\n",
    "from osgeo import gdal, ogr, gdal_array # I/O image data\n",
    "import joblib\n",
    "import numpy as np # math and array handling\n",
    "import matplotlib.pyplot as plt # plot figures\n",
    "from matplotlib.colors import ListedColormap # to import certain defined color palettes for plotting your results\n",
    "from sklearn.ensemble import RandomForestClassifier # classifier\n",
    "import pandas as pd # handling large data as table sheets\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix  # calculating measures for accuracy assessment\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skimage import exposure  # for adjustment of rasterstack (histogram equalization, etc)\n",
    "\n",
    "# Tell GDAL to throw Python exceptions, and register all drivers\n",
    "gdal.UseExceptions()\n",
    "gdal.AllRegister()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV-File einlesen X_concat\n",
    "input_name = 'X_concat TDX_3.csv'\n",
    "input_folder = r\"E:\\CSV Data\\TSX\"\n",
    "input_data = os.path.join(input_folder, input_name)\n",
    "\n",
    "df = pd.read_csv(input_data, index_col = 0)\n",
    "display(df)\n",
    "array_X= df.to_numpy()\n",
    "display(array_X, type(array_X))\n",
    "\n",
    "# CSV-File einlesen y_concat\n",
    "input_name = 'y_concat TDX_3.csv'\n",
    "input_folder = r\"E:\\CSV Data\\TSX\"\n",
    "input_data = os.path.join(input_folder, input_name)\n",
    "\n",
    "df = pd.read_csv(input_data, index_col = 0)\n",
    "display(df)\n",
    "array_y= df.to_numpy()\n",
    "\n",
    "display(array_y, type(array_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_concat = array_X\n",
    "y_concat = array_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many cores should be used?\n",
    "n_cores = -1\n",
    "# -1 -> all available cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klassen,Anzahl=np.unique(y_concat, return_index=False, return_inverse=False, return_counts=True, axis=None)\n",
    "print(Anzahl)\n",
    "print(klassen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_concat, y_concat, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "print('Our X matrix is sized: {sz}'.format(sz=X_resampled.shape))\n",
    "print('Our y array is sized: {sz}'.format(sz=y_resampled.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_resampled\n",
    "y_train = y_resampled\n",
    "print('Our X matrix is sized: {sz}'.format(sz=X_train.shape))\n",
    "print('Our y array is sized: {sz}'.format(sz=y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klassen,Anzahl=np.unique(y_train, return_index=False, return_inverse=False, return_counts=True, axis=None)\n",
    "print(Anzahl)\n",
    "print(klassen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RANDOM FOREST TRAIN / TEST\n",
    "est = 500\n",
    "rf = RandomForestClassifier(n_estimators=est, verbose=1, n_jobs=n_cores, random_state=42, max_features =\"sqrt\")\n",
    "X_train = np.nan_to_num(X_train)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction class for the testing set\n",
    "X_test = np.nan_to_num(X_test)\n",
    "y_pred = rf.predict(X_test)\n",
    "print('Shape prediction {}'.format(y_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "# View confusion matrix for test data and predictions\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model performance\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where my data is located\n",
    "folder_NewData_src = r\"C:\\Users\\rwolff\\Documents\\Lac Bam SSD\\Aufnahmen Clipped\\Neue Aufnahmen\\Neue Aufnahmen TDX_3 Clipped\"\n",
    "folder_src_shape = r\"C:\\Users\\rwolff\\Documents\\Lac Bam SSD\\Vektordaten_Merged all\"\n",
    "\n",
    "# path where I want to save my results \n",
    "folder_results = r\"E:\\results\\500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "directory = folder_NewData_src\n",
    "directory_shapes = folder_src_shape\n",
    "iterator = 0\n",
    "\n",
    "for filename_tif, filename_shape in zip(os.listdir(directory),[f for f in os.listdir(directory_shapes) if f.endswith('.shp')]):\n",
    "  file = os.path.join(directory, filename_tif)\n",
    "  if os.path.isfile(file):\n",
    "    print(file)\n",
    "    s2_stack=file\n",
    "    print(s2_stack)\n",
    "    filename = filename_tif\n",
    "# load image data\n",
    "#In this script we are Using gdal.open() instead of rio.open()\n",
    "    img_ds = gdal.Open(s2_stack, gdal.GA_ReadOnly)\n",
    "\n",
    "    img = np.zeros((img_ds.RasterYSize, img_ds.RasterXSize, img_ds.RasterCount),\n",
    "               gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "    for b in range(img.shape[2]):\n",
    "        img[:, :, b] = img_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "\n",
    "    print(\"Raster format is:\", gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "    \n",
    "# store the variables above in a more meaningful way. You will use these variables later.\n",
    "    row = img_ds.RasterYSize\n",
    "    col = img_ds.RasterXSize\n",
    "    band_number = img_ds.RasterCount\n",
    "    \n",
    "    print(\"Raster number of rows: {}\".format(row))\n",
    "    print(\"Raster number of columns: {}\".format(col))\n",
    "    print(\"Raster number of bands: {}\".format(band_number))\n",
    "    \n",
    "# Take our full image and reshape into long 2d array (nrow * ncol, nband) for classification\n",
    "    new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n",
    "    img_as_array = img[:, :, : int(img.shape[2])].reshape(new_shape)\n",
    "\n",
    "    print('Reshaped from {o} to {n}'.format(o=img.shape, n=img_as_array.shape))\n",
    "    \n",
    "    img_as_array = np.nan_to_num(img_as_array)\n",
    "    \n",
    "    training = folder_src_shape + \"\\\\\" + filename_shape\n",
    "    \n",
    "# Now predict for each pixel\n",
    "    #img_as_array = np.nan_to_num(img_as_array)\n",
    "    class_prediction = rf.predict(img_as_array)\n",
    "    print('Shape prediction {}'.format(class_prediction.shape))\n",
    "\n",
    "    class_prediction = class_prediction.reshape(img[:, :, 0].shape)\n",
    "    print('Reshaped back to {}'.format(class_prediction.shape))\n",
    "# assing colors to each class. The order of the colors depends on the order of the landclasses\n",
    "    custom_cmap = ListedColormap([\"orange\",\"blue\",\"green\",\"purple\"])\n",
    "# for example, here water = \"lightseagreen\"\n",
    "\n",
    "# plot your classification\n",
    "    fig,ax = plt.subplots(figsize=(20,20))\n",
    "    ax.set_title('Random Forest Classification\\n n-trees = 200 TDX 1', fontsize = 35) # use '\\n' to start a new line\n",
    "    \n",
    "# indicate which file will be plotted, add colors\n",
    "    plot_rf =ax.imshow(class_prediction, cmap=custom_cmap) \n",
    "# set parameters for colorbar\n",
    "    cbar_rf = plt.colorbar(plot_rf,shrink=0.6) \n",
    "    cbar_rf.set_ticks([1,2,3,4])\n",
    "    cbar_rf.set_ticklabels([\"fields\", \"open water\", \"flooded vegetation\", \"wetlands\"])\n",
    "    cbar_rf.ax.tick_params(labelsize=25) # adapt font size of ticks\n",
    "# show your plot\n",
    "#plt.show()\n",
    "    \n",
    " # TEST BLOCK ZUM SPEICHERN DER DATEN !!!! \n",
    "    plotname = \"\\\\\" + filename[8:-4]\n",
    "    print(folder_results)\n",
    "    print(plotname)\n",
    "# export your plot as an PNG image\n",
    "#fig.savefig(os.path.join(folder_results, \"plotname1.png\"), bbox_inches='tight')\n",
    "#fig.savefig(os.path.join(folder_results, \"FIG%d%d.png\"), bbox_inches='tight')\n",
    "    fig.savefig(os.path.join(folder_results, str(filename)+\".png\"), bbox_inches='tight')\n",
    "    \n",
    "# define where the image will be saved\n",
    "#classification_image=os.path.join(folder_results,'plotname1.tif')\n",
    "    classification_image=os.path.join(folder_results, str(filename)+'.tif')\n",
    "    cols = img.shape[1]\n",
    "    rows = img.shape[0]\n",
    "\n",
    "# define structure of your output file\n",
    "    driver = gdal.GetDriverByName(\"gtiff\")\n",
    "    outdata = driver.Create(classification_image, cols, rows, 1, gdal.GDT_Byte)\n",
    "    outdata.SetGeoTransform(img_ds.GetGeoTransform()) ##sets same geotransform as input\n",
    "    outdata.SetProjection(img_ds.GetProjection()) ##sets same projection as input\n",
    "\n",
    "# specify which image you want to save\n",
    "    outdata.GetRasterBand(1).WriteArray(class_prediction)\n",
    "\n",
    "#saves to disk!!\n",
    "    outdata.FlushCache() \n",
    "\n",
    "    print('Image saved to: {}'.format(classification_image)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST SPEICHERN!  mit JOBLIB TEST!!!!!! \n",
    "#import joblib\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#joblib.dump(rf, \"RandomForest_TDX_2_over.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
